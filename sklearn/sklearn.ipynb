{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression using `linear_model` in `sklearn`\n",
    "\n",
    "Apart from `statsmodels`, there is another package namely `sklearn` that can be used to perform linear regression. We will use the `linear_model` library from `sklearn` to build the model. \n",
    "\n",
    "There's one small step that we need to add, though. When there's only a single feature, we need to add an additional column in order for the linear regression fit to be performed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3   12.0\n",
       "3  151.5   41.3       58.5   16.5\n",
       "4  180.8   10.8       58.4   17.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the given CSV file, and view some sample records\n",
    "\n",
    "advertising = pd.read_csv(\"advertising.csv\")\n",
    "advertising.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Steps in model building using `sklearn`\n",
    "\n",
    "We first assign the feature variable, `TV`, in this case, to the variable `X` and the response variable, `Sales`, to the variable `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = advertising['TV']\n",
    "y = advertising['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n",
    "\n",
    "You now need to split our variable into training and testing sets. You'll perform this by importing `train_test_split` from the `sklearn.model_selection` library. It is usually a good practice to keep 70% of the data in your train dataset and the rest 30% in your test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X_train to (140, 1)\n",
    "X_train_lm = X_train.values.reshape(-1,1)\n",
    "X_test_lm = X_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps in sklearn model building\n",
    "\n",
    "# 1. Create an object of linear regression\n",
    "lm = LinearRegression()\n",
    "\n",
    "# 2. Fit the model\n",
    "lm.fit(X_train_lm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05454575]\n",
      "6.948683200001357\n"
     ]
    }
   ],
   "source": [
    "# 3. see the params, make predictions (train, test)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equationwe get is the same as what we got before!\n",
    "\n",
    "$ Sales = 6.948 + 0.054* TV $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_train_pred = lm.predict(X_train_lm)\n",
    "y_test_pred = lm.predict(X_test_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157933136480389\n",
      "0.7921031601245662\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate the model\n",
    "print(r2_score(y_true=y_train, y_pred=y_train_pred))\n",
    "print(r2_score(y_true=y_test, y_pred=y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Addressing some common questions/doubts on Simple Linear Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Why is it called 'R-squared'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.90321277]\n",
      " [0.90321277 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "corrs = np.corrcoef(X_train, y_train)\n",
    "print(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157933136480384"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs[0,1] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation (Pearson) is also called **\"r\"** or **\"Pearson's R\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is a good RMSE? Is there some RMSE that I should aim for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE:\n",
    " - depends on the units of the Y variables\n",
    " - is NOT a normalized measure\n",
    " \n",
    "While it can't really tell you of the gooodness of the particular model, it can help you compare models. \n",
    "\n",
    "A better measure is R squared, which is normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Does scaling have an impact on the model? When should I scale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the true benefits of scaling will be apparent during future modules, at this juncture we can discuss if it has an impact on the model.\n",
    "\n",
    "We'll rebuild the model after scaling the predictor and see what changes.\n",
    "\n",
    "The most popular methods for scaling:\n",
    "1. Min-Max Scaling\n",
    "2. Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKit Learn has these scaling utilities handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One aspect that you need to take care of is that the 'fit_transform' can be performed on 2D arrays only. So you need to\n",
    "# reshape your 'X_train_scaled' and 'y_trained_scaled' data in order to perform the standardisation.\n",
    "X_train_scaled = X_train.values.reshape(-1,1)\n",
    "y_train_scaled = y_train.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object using StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "#'Fit' and transform the train set; and transform using the fit on the test set later\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "y_train_scaled = scaler.fit_transform(y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and sd for X_train_scaled: 1.45915026093592e-16 0.7071067811865476\n",
      "mean and sd for y_train_scaled: -2.5376526277146434e-16 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"mean and sd for X_train_scaled:\", np.mean(X_train_scaled), np.std(X_train_scaled))\n",
    "print(\"mean and sd for y_train_scaled:\", np.mean(y_train_scaled), np.std(y_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit the regression line following exactly the same steps as done before\n",
    "X_train_scaled = sm.add_constant(X_train_scaled)\n",
    "\n",
    "lr_scaled = sm.OLS(y_train_scaled, X_train_scaled).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.41233725e-16,  0.00000000e+00,  9.03212773e-01])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the parameters\n",
    "lr_scaled.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might notice, the value of the parameters have changed since we have changed the scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the statistics of the model, to see if any other aspect of the model has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.816\n",
      "Model:                            OLS   Adj. R-squared:                  0.814\n",
      "Method:                 Least Squares   F-statistic:                     611.2\n",
      "Date:                Wed, 27 May 2020   Prob (F-statistic):           1.52e-52\n",
      "Time:                        00:17:42   Log-Likelihood:                -321.12\n",
      "No. Observations:                 140   AIC:                             646.2\n",
      "Df Residuals:                     138   BIC:                             652.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          6.9487      0.385     18.068      0.000       6.188       7.709\n",
      "x1             0.0545      0.002     24.722      0.000       0.050       0.059\n",
      "==============================================================================\n",
      "Omnibus:                        0.027   Durbin-Watson:                   2.196\n",
      "Prob(Omnibus):                  0.987   Jarque-Bera (JB):                0.150\n",
      "Skew:                          -0.006   Prob(JB):                        0.928\n",
      "Kurtosis:                       2.840   Cond. No.                         328.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lr_scaled.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model statistics and goodness of fit remain unchanged.\n",
    "\n",
    "##### So why scale at all?\n",
    "- Helps with interpretation (we'll be able to appreciate this better in later modules)\n",
    "- Faster convergence of gradient descent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
